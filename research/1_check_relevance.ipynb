{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Check Question Relevance\n",
    "\n",
    "This notebook tests the first node in our RAG pipeline. Its purpose is to make an initial LLM call to determine if the user's question is related to emissions. This prevents the system from performing an unnecessary document search for off-topic questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/90/p8kgtvm572d51cr90k19v_580000gn/T/ipykernel_62643/916712105.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=MODEL_NAME, temperature=0)\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "MODEL_NAME = \"llama3\"\n",
    "llm = Ollama(model=MODEL_NAME, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_relevance(state: dict, llm) -> dict:\n",
    "    \"\"\"\n",
    "    Checks if the question is relevant to the document context.\n",
    "    This function is defined locally for experimentation.\n",
    "    \"\"\"\n",
    "    print(\"---CHECKING QUESTION RELEVANCE---\")\n",
    "    question = state['question']\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "    You are an expert in oil and gas regulations. Your task is to determine if a user's question is related to 'oil and gas emissions' or 'emissions' in general.\n",
    "    Answer with a simple 'yes' or 'no'.\n",
    "\n",
    "    User question: \"{question}\"\n",
    "\n",
    "    Is this question related to emissions? (yes/no):\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"question\"])\n",
    "    relevance_checker = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    relevance_response = relevance_checker.invoke({\"question\": question})\n",
    "    \n",
    "    if \"yes\" in relevance_response.lower():\n",
    "        print(\"---QUESTION IS RELEVANT---\")\n",
    "        return {\"is_relevant\": True}\n",
    "    else:\n",
    "        print(\"---QUESTION IS NOT RELEVANT---\")\n",
    "        return {\"is_relevant\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with a Relevant Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECKING QUESTION RELEVANCE---\n",
      "---QUESTION IS RELEVANT---\n",
      "{'is_relevant': True}\n"
     ]
    }
   ],
   "source": [
    "relevant_question = \"What are the monitoring requirements for flare gas?\"\n",
    "state = {\"question\": relevant_question}\n",
    "\n",
    "result = check_relevance(state, llm)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with an Irrelevant Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECKING QUESTION RELEVANCE---\n",
      "---QUESTION IS NOT RELEVANT---\n",
      "{'is_relevant': False}\n"
     ]
    }
   ],
   "source": [
    "irrelevant_question = \"What is the capital of France?\"\n",
    "state = {\"question\": irrelevant_question}\n",
    "\n",
    "result = check_relevance(state, llm)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ig-reel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
